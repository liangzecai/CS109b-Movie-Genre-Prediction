{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Variables for text analysis\n",
    "\n",
    "For variables \"title\",\"plot outline\", \"plot\", \"mpaa_reason\", \"tagline_TMDB\", we'd like to apply text analysis to extract the key words that might be informative for predicting genre.\n",
    "\n",
    "To do this, we first perform routine bag-od-words analysis to filter out non-word items (puctuations and numbers) of the text, and turn the stirn into frequency counts of different worlds.\n",
    "\n",
    "For each variable, we would then apply PCA to the matrix of bag-of-word, and keep the top PCs (the number of PCs to choose will be decided by the variance they can explain, but for now I'll choose 10 PCs as demonstration). This new matrix would become the new feature matrix for this specific variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 43)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"feature_multi_top100.txt\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_words = []\n",
    "colname = \"plot outline\"\n",
    "\n",
    "df_col = df[colname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "col_words = []\n",
    "\n",
    "for i in range(len(df_col)):\n",
    "    \n",
    "    if type(df_col[i]) == str: \n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \" , df_col[i])\n",
    "\n",
    "        lower_case = letters_only.lower()  \n",
    "        words = lower_case.split()\n",
    "\n",
    "        meaningful_words = lower_case.split()\n",
    "        words = ( \" \".join(meaningful_words))\n",
    "    \n",
    "    else: words = \"NA\"\n",
    "\n",
    "    col_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run \"pip install --user --install-option=\"--prefix=\" -U scikit-learn\" on terminal\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                                         tokenizer = None,    \n",
    "                                         preprocessor = None, \n",
    "                                         stop_words = None,   \n",
    "                                         max_features = 5000)\n",
    "\n",
    "col_data = vectorizer.fit_transform(col_words)\n",
    "col_data = pd.DataFrame(col_data.toarray())\n",
    "\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.concat([df[\"imdb_ids\"], col_data], axis = 1)\n",
    "col_names = [\"imdb_ids\"] + vocab\n",
    "df_new.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_ids</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>absent</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accomplices</th>\n",
       "      <th>accused</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>wreak</th>\n",
       "      <th>wreaks</th>\n",
       "      <th>writer</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zefram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425473</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>411267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1085 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdb_ids  ability  able  about  absent  accident  accidentally  \\\n",
       "0    113101        0     0      0       0         0             0   \n",
       "1    425473        0     0      0       0         0             0   \n",
       "2     76759        0     0      0       0         0             0   \n",
       "3    266543        0     0      0       0         0             0   \n",
       "4    411267        0     0      0       0         0             0   \n",
       "\n",
       "   accomplices  accused  acting   ...    works  world  wreak  wreaks  writer  \\\n",
       "0            0        0       0   ...        0      0      0       0       0   \n",
       "1            0        0       0   ...        0      0      0       0       0   \n",
       "2            0        0       0   ...        0      1      0       0       0   \n",
       "3            0        0       0   ...        0      0      0       0       0   \n",
       "4            0        0       0   ...        0      0      0       0       0   \n",
       "\n",
       "   year  years  york  young  zefram  \n",
       "0     1      0     0      0       0  \n",
       "1     0      0     0      0       0  \n",
       "2     0      0     0      0       0  \n",
       "3     0      0     0      0       0  \n",
       "4     0      1     0      1       0  \n",
       "\n",
       "[5 rows x 1085 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1085)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the text analysis on the first 100 rows generate bag-of-words of size 1085. The next step is to apply PCA to reduce the feature dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "df_pca = pd.DataFrame(pca.fit_transform(col_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new_pca = pd.concat([df[\"imdb_ids\"], df_pca], axis = 1)\n",
    "\n",
    "col_names = [\"imdb_ids\"]\n",
    "for i in range(10):\n",
    "    i_name = \"plot_outline_PC\" + str(i)\n",
    "    col_names.append(i_name)\n",
    "    \n",
    "df_new_pca.columns = col_names\n",
    "df_new_pca.to_csv(\"plot_outline_text_analysis.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imdb_ids</th>\n",
       "      <th>plot_outline_PC0</th>\n",
       "      <th>plot_outline_PC1</th>\n",
       "      <th>plot_outline_PC2</th>\n",
       "      <th>plot_outline_PC3</th>\n",
       "      <th>plot_outline_PC4</th>\n",
       "      <th>plot_outline_PC5</th>\n",
       "      <th>plot_outline_PC6</th>\n",
       "      <th>plot_outline_PC7</th>\n",
       "      <th>plot_outline_PC8</th>\n",
       "      <th>plot_outline_PC9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>113101</td>\n",
       "      <td>-1.315679</td>\n",
       "      <td>-0.934888</td>\n",
       "      <td>0.347586</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>0.315814</td>\n",
       "      <td>-0.221987</td>\n",
       "      <td>-0.553449</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>-0.543138</td>\n",
       "      <td>-0.415480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>425473</td>\n",
       "      <td>-1.433989</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>-0.181678</td>\n",
       "      <td>0.771971</td>\n",
       "      <td>-0.805442</td>\n",
       "      <td>-0.060474</td>\n",
       "      <td>0.382522</td>\n",
       "      <td>-0.603814</td>\n",
       "      <td>0.145042</td>\n",
       "      <td>-0.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76759</td>\n",
       "      <td>1.662408</td>\n",
       "      <td>1.688841</td>\n",
       "      <td>0.339102</td>\n",
       "      <td>0.009727</td>\n",
       "      <td>-1.804681</td>\n",
       "      <td>-0.567208</td>\n",
       "      <td>-1.597238</td>\n",
       "      <td>-1.214306</td>\n",
       "      <td>1.035848</td>\n",
       "      <td>-0.069215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>266543</td>\n",
       "      <td>-0.489223</td>\n",
       "      <td>1.600604</td>\n",
       "      <td>0.524656</td>\n",
       "      <td>0.294343</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>-0.434347</td>\n",
       "      <td>0.237392</td>\n",
       "      <td>0.412804</td>\n",
       "      <td>-0.307850</td>\n",
       "      <td>-0.274183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>411267</td>\n",
       "      <td>-0.073453</td>\n",
       "      <td>-0.043161</td>\n",
       "      <td>0.734877</td>\n",
       "      <td>-0.353448</td>\n",
       "      <td>-0.696221</td>\n",
       "      <td>1.357004</td>\n",
       "      <td>0.443975</td>\n",
       "      <td>1.993990</td>\n",
       "      <td>0.919077</td>\n",
       "      <td>0.473163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  imdb_ids  plot_outline_PC0  plot_outline_PC1  plot_outline_PC2  \\\n",
       "0           0    113101         -1.315679         -0.934888          0.347586   \n",
       "1           1    425473         -1.433989         -0.003703         -0.181678   \n",
       "2           2     76759          1.662408          1.688841          0.339102   \n",
       "3           3    266543         -0.489223          1.600604          0.524656   \n",
       "4           4    411267         -0.073453         -0.043161          0.734877   \n",
       "\n",
       "   plot_outline_PC3  plot_outline_PC4  plot_outline_PC5  plot_outline_PC6  \\\n",
       "0          0.373653          0.315814         -0.221987         -0.553449   \n",
       "1          0.771971         -0.805442         -0.060474          0.382522   \n",
       "2          0.009727         -1.804681         -0.567208         -1.597238   \n",
       "3          0.294343          0.025439         -0.434347          0.237392   \n",
       "4         -0.353448         -0.696221          1.357004          0.443975   \n",
       "\n",
       "   plot_outline_PC7  plot_outline_PC8  plot_outline_PC9  \n",
       "0          0.063865         -0.543138         -0.415480  \n",
       "1         -0.603814          0.145042         -0.058100  \n",
       "2         -1.214306          1.035848         -0.069215  \n",
       "3          0.412804         -0.307850         -0.274183  \n",
       "4          1.993990          0.919077          0.473163  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_pca = pd.read_csv(\"plot_outline_text_analysis.txt\")\n",
    "df_new_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ipykernel_py2]",
   "language": "python",
   "name": "Python [ipykernel_py2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
