{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Function to apply text analysis to a column with `colname` in the data file `filename`\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "### Input ###\n",
    "        # colname: colname name of the variable\n",
    "        # filename: filename of the data\n",
    "        # var_explain: the threshold of the variance explained to select the top PCs in PCA analysis, \n",
    "                        # value between (0,1)\n",
    "        # savename: name of the data file generated\n",
    "        \n",
    "### Input ###\n",
    "        # a data file with each column named as `colname_pci`, saved in local directory as `savename`\n",
    "#----------------------------------------------------------------------------------------------------        \n",
    "\n",
    "\n",
    "\n",
    "def text_analysis(colname = \"plot outline\", filename = \"feature_multi_top100.txt\", var_explain = 0.9,\n",
    "                  savename = \"plot_outline_text_analysis.csv\"):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### --------------- Load Data --------------- ###\n",
    "    df = pd.read_csv(filename)\n",
    "    df_col = df[colname]\n",
    "    \n",
    "    \n",
    "    ## --------------- Bag-of-Words --------------- ##\n",
    "    \n",
    "    ## string to list\n",
    "    import re\n",
    "    col_words = []\n",
    "    \n",
    "    for i in range(len(df_col)):\n",
    "    \n",
    "        if type(df_col[i]) == str: \n",
    "            letters_only = re.sub(\"[^a-zA-Z]\", \" \" , df_col[i]) # remove non-letter\n",
    "            lower_case = letters_only.lower().split()   # Convert to lower case # Split into words\n",
    "            \n",
    "            # avoid downloading nltk\n",
    "            # from NLTK stopwords https://pythonprogramming.net/stop-words-nltk-tutorial/\n",
    "            stops = {'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', \n",
    "                     'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', \n",
    "                     'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', \n",
    "                     's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', \n",
    "                     'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', \n",
    "                     'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', \n",
    "                     'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', \n",
    "                     'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', \n",
    "                     'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', \n",
    "                     'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', \n",
    "                     'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', \n",
    "                     'it', 'how', 'further', 'was', 'here', 'than'} \n",
    "            meaningful_words = [w for w in lower_case if not w in stops]  # Remove stop words from \"words\"\n",
    "            \n",
    "            words = ( \" \".join(meaningful_words))\n",
    "    \n",
    "        else: words = \"NA\"\n",
    "       \n",
    "        col_words.append(words)\n",
    "        \n",
    "        \n",
    "    \n",
    "    ## list to vector\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    # Initialize the \"CountVectorizer\" object\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                                 tokenizer = None,    \n",
    "                                 preprocessor = None, \n",
    "                                 stop_words = None,   \n",
    "                                 max_features = 10000)\n",
    "\n",
    "    col_data = vectorizer.fit_transform(col_words)\n",
    "    col_data = col_data.toarray()\n",
    "\n",
    "    \n",
    "    ## --------------- PCA --------------- ##\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components = var_explain, svd_solver = \"full\") # keep the first n PCs with 90% variance explained\n",
    "    df_pca = pd.DataFrame(pca.fit_transform(col_data))\n",
    "    \n",
    "    ## ------------- Align with imdb_id and save ------------##\n",
    "    \n",
    "    df_new_pca = pd.concat([df[\"imdb_ids\"], df_pca], axis = 1)\n",
    "\n",
    "    col_names = [\"imdb_ids\"]\n",
    "    for i in range(df_pca.shape[1]):\n",
    "        i_name = colname + \"_PC\" + str(i)\n",
    "        col_names.append(i_name)\n",
    "    \n",
    "    df_new_pca.columns = col_names\n",
    "    df_new_pca.to_csv(savename, index = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_analysis(colname = \"title\", filename = \"imdb_top100_data_parse.txt\", var_explain = 0.6,\n",
    "                  savename = \"top100_title_text_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_ids</th>\n",
       "      <th>title_PC0</th>\n",
       "      <th>title_PC1</th>\n",
       "      <th>title_PC2</th>\n",
       "      <th>title_PC3</th>\n",
       "      <th>title_PC4</th>\n",
       "      <th>title_PC5</th>\n",
       "      <th>title_PC6</th>\n",
       "      <th>title_PC7</th>\n",
       "      <th>title_PC8</th>\n",
       "      <th>...</th>\n",
       "      <th>title_PC26</th>\n",
       "      <th>title_PC27</th>\n",
       "      <th>title_PC28</th>\n",
       "      <th>title_PC29</th>\n",
       "      <th>title_PC30</th>\n",
       "      <th>title_PC31</th>\n",
       "      <th>title_PC32</th>\n",
       "      <th>title_PC33</th>\n",
       "      <th>title_PC34</th>\n",
       "      <th>title_PC35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113101</td>\n",
       "      <td>-0.079327</td>\n",
       "      <td>-0.011353</td>\n",
       "      <td>-0.029817</td>\n",
       "      <td>-0.043224</td>\n",
       "      <td>-0.029065</td>\n",
       "      <td>-4.421113e-17</td>\n",
       "      <td>-0.045250</td>\n",
       "      <td>1.423015e-18</td>\n",
       "      <td>-1.786223e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.760413e-15</td>\n",
       "      <td>0.096727</td>\n",
       "      <td>-6.794354e-15</td>\n",
       "      <td>-0.129179</td>\n",
       "      <td>-0.039168</td>\n",
       "      <td>-0.049688</td>\n",
       "      <td>-4.599880e-18</td>\n",
       "      <td>-7.283144e-18</td>\n",
       "      <td>6.064175e-17</td>\n",
       "      <td>2.759928e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425473</td>\n",
       "      <td>-0.088179</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>-0.040108</td>\n",
       "      <td>-0.059759</td>\n",
       "      <td>-0.042426</td>\n",
       "      <td>2.918354e-16</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>-1.867128e-16</td>\n",
       "      <td>-2.871110e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.454471e+00</td>\n",
       "      <td>-0.343248</td>\n",
       "      <td>1.165585e-14</td>\n",
       "      <td>0.136044</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>2.925731e-16</td>\n",
       "      <td>-3.216521e-16</td>\n",
       "      <td>-6.671028e-16</td>\n",
       "      <td>8.106811e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76759</td>\n",
       "      <td>0.656727</td>\n",
       "      <td>-0.024725</td>\n",
       "      <td>-0.016591</td>\n",
       "      <td>-0.014724</td>\n",
       "      <td>-0.008640</td>\n",
       "      <td>-6.501939e-15</td>\n",
       "      <td>-0.013441</td>\n",
       "      <td>-8.728284e-17</td>\n",
       "      <td>-3.070047e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.573449e-16</td>\n",
       "      <td>0.026175</td>\n",
       "      <td>-7.075205e-16</td>\n",
       "      <td>-0.017686</td>\n",
       "      <td>-0.063346</td>\n",
       "      <td>-0.008722</td>\n",
       "      <td>-6.192331e-16</td>\n",
       "      <td>-1.851807e-16</td>\n",
       "      <td>3.096729e-16</td>\n",
       "      <td>-5.711407e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266543</td>\n",
       "      <td>-0.079327</td>\n",
       "      <td>-0.011353</td>\n",
       "      <td>-0.029817</td>\n",
       "      <td>-0.043224</td>\n",
       "      <td>-0.029065</td>\n",
       "      <td>7.187369e-16</td>\n",
       "      <td>-0.045250</td>\n",
       "      <td>-1.863760e-16</td>\n",
       "      <td>-6.857209e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.152621e-15</td>\n",
       "      <td>0.096727</td>\n",
       "      <td>-5.822481e-15</td>\n",
       "      <td>-0.129179</td>\n",
       "      <td>-0.039168</td>\n",
       "      <td>-0.049688</td>\n",
       "      <td>-1.168951e-01</td>\n",
       "      <td>1.538504e-01</td>\n",
       "      <td>-3.960839e-03</td>\n",
       "      <td>-1.546434e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>411267</td>\n",
       "      <td>-0.080060</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>-0.031466</td>\n",
       "      <td>-0.045981</td>\n",
       "      <td>-0.031436</td>\n",
       "      <td>1.504055e-15</td>\n",
       "      <td>-0.049616</td>\n",
       "      <td>-3.092303e-16</td>\n",
       "      <td>1.947978e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.603433e-15</td>\n",
       "      <td>0.345515</td>\n",
       "      <td>6.015010e-01</td>\n",
       "      <td>0.447650</td>\n",
       "      <td>0.102126</td>\n",
       "      <td>0.024368</td>\n",
       "      <td>6.012173e-16</td>\n",
       "      <td>-1.055284e-16</td>\n",
       "      <td>1.796691e-16</td>\n",
       "      <td>-1.591275e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdb_ids  title_PC0  title_PC1  title_PC2  title_PC3  title_PC4  \\\n",
       "0    113101  -0.079327  -0.011353  -0.029817  -0.043224  -0.029065   \n",
       "1    425473  -0.088179  -0.015068  -0.040108  -0.059759  -0.042426   \n",
       "2     76759   0.656727  -0.024725  -0.016591  -0.014724  -0.008640   \n",
       "3    266543  -0.079327  -0.011353  -0.029817  -0.043224  -0.029065   \n",
       "4    411267  -0.080060  -0.011935  -0.031466  -0.045981  -0.031436   \n",
       "\n",
       "      title_PC5  title_PC6     title_PC7     title_PC8      ...       \\\n",
       "0 -4.421113e-17  -0.045250  1.423015e-18 -1.786223e-17      ...        \n",
       "1  2.918354e-16  -0.068966 -1.867128e-16 -2.871110e-16      ...        \n",
       "2 -6.501939e-15  -0.013441 -8.728284e-17 -3.070047e-16      ...        \n",
       "3  7.187369e-16  -0.045250 -1.863760e-16 -6.857209e-16      ...        \n",
       "4  1.504055e-15  -0.049616 -3.092303e-16  1.947978e-17      ...        \n",
       "\n",
       "     title_PC26  title_PC27    title_PC28  title_PC29  title_PC30  title_PC31  \\\n",
       "0  1.760413e-15    0.096727 -6.794354e-15   -0.129179   -0.039168   -0.049688   \n",
       "1  1.454471e+00   -0.343248  1.165585e-14    0.136044    0.037079    0.017544   \n",
       "2 -5.573449e-16    0.026175 -7.075205e-16   -0.017686   -0.063346   -0.008722   \n",
       "3  1.152621e-15    0.096727 -5.822481e-15   -0.129179   -0.039168   -0.049688   \n",
       "4  1.603433e-15    0.345515  6.015010e-01    0.447650    0.102126    0.024368   \n",
       "\n",
       "     title_PC32    title_PC33    title_PC34    title_PC35  \n",
       "0 -4.599880e-18 -7.283144e-18  6.064175e-17  2.759928e-17  \n",
       "1  2.925731e-16 -3.216521e-16 -6.671028e-16  8.106811e-16  \n",
       "2 -6.192331e-16 -1.851807e-16  3.096729e-16 -5.711407e-16  \n",
       "3 -1.168951e-01  1.538504e-01 -3.960839e-03 -1.546434e-02  \n",
       "4  6.012173e-16 -1.055284e-16  1.796691e-16 -1.591275e-17  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"top100_title_text_analysis.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ipykernel_py2]",
   "language": "python",
   "name": "Python [ipykernel_py2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
