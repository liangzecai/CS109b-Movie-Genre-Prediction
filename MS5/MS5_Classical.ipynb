{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS109b Final Project\n",
    "\n",
    "# Milestone 5 CLASSICAL PART\n",
    "\n",
    "\n",
    "by Danqing Wang, Wenshan Zheng, Zecai Liang\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Group 1: ['year', 'rating', 'votes', 'popularity_TMDB', 'runtime_TMDB']\n",
    "- variable ['year', 'rating', 'votes'] have missing values as 'NaN': we impute the missing value in training and test data with the mean value of training data\n",
    "- [popularity_TMDB'] have missing values as 0: we impute the missing value in training and test data with the mean value of training data\n",
    "- ['runtime_TMDB'] have missing values as 0 and as 'NaN': we perform the same mean imputation\n",
    "\n",
    "### Variables Group 2: ['title', 'plot', 'plot outline', 'overview_TMDB', 'tagline_TMDB']\n",
    "- we combine all the text information for one movie, split the paragraph of string into bag-of-words, and return the top 30 PCs\n",
    "- we used the PCA model trained from the training data to transform the test data\n",
    "\n",
    "### Variable Group 3: ['mpaa']\n",
    "- we extracted the text as the reason for 'mpaa', and applied similar text analysis as variable group 2, and return return the top 10 PCs\n",
    "\n",
    "### Variable Group 4: ['director', 'cast', 'production company', 'writer']\n",
    "- ['director', 'writer']: We analyse the training data and rank the top few most representative directors/writer in each genre. We extract the top director/writer from each genre and use them as new predictor columns, and transform the training data into a new dataframe using one-hot-encoding. We also form a similar dataframe for the test dataset using the same columns. Since the dataframes are sparse, we expect some of the directors/writers selected by the training data analysis not represented at all in the test dataset, and therefore will have columns with NULL values. We replace these NULL values with 0s.\n",
    "- ['cast', 'production companies']: We analyse the training data and rank the top 5 most representative cast members/production companies in each genre. We extract the lists of cast members/production companies and use one-hot-encoding to form a dataframe of 1s and 0s consisting of all movies in the training set. We then perform PCA on the dataframe and select the top five PCs for both cast and production companies. We then use these PCs to transform the test dataset into the new basis, and prepare it for model fitting.\n",
    "\n",
    "### Variables Group 5: ['animation department', 'original music']\n",
    "- we extract the number of person ID for both department, representing the number of staff working there\n",
    "\n",
    "### Variables Group 6: ['countries']\n",
    "- we return the number of countries for each movie with variable name 'country_n'\n",
    "- we also record if the movie is produced in one of the following major countries: ['usa', 'france', 'uk', 'germany', 'italy', 'canada', 'japan', 'india', 'spain'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response: ['genres']\n",
    "\n",
    "- There are in total 28 genres in imdb, which are: 'Action', 'Adventure', 'Comedy', 'Crime', 'Fantasy', 'Family', 'Romance', 'Horror', 'Reality-TV', 'Western', 'Documentary', 'Biography', 'News', 'Film-Noir', 'Drama', 'Animation', 'Sci-Fi', 'Thriller', 'Short', 'Mystery', 'Sport', 'War', 'History', 'Game-Show', 'Music', 'Musical' and 'Talk-Show'.\n",
    "Becaues 'Music' and 'Musical' is very similar, we combine these 2 genres thus we have 27 genres.\n",
    "\n",
    "- In tmdb, there are 19 genres. However, most genres in tmdb are included in imdb, the only exception is 'TV movie' thus it is added to genre list and now we have 28 genres.\n",
    "\n",
    "- Then we assign each movie's genres into a multi binomial genre list with 28 values correspongding to if it belongs to each of these 28 genres.\n",
    "\n",
    "- Then we found that 'TV movie', 'Game-Show', 'Reality-TV', 'Talk-Show', 'News' and 'Film-Noir' only have less then 300 movies assigned, which is far less than our 25K moives number, so we combine these 6 genres into a genre'Other'.\n",
    "\n",
    "- After these, we have in total 23 genres which are 'Action', 'Adventure', 'Comedy', 'Crime', 'Fantasy', 'Family', 'Romance', 'Horror', 'Western', 'Documentary', 'Biography', 'Drama', 'Animatio', 'Sci-Fi', 'Thriller', 'Short', 'Mystery', 'Sport', 'War', 'History', 'Music', 'Foreign' and 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_full = pd.read_csv('data_feature_4865.csv')\n",
    "y_full = pd.read_csv('y_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'imdb_ids', u'title', u'director', u'distributors',\n",
       "       u'year', u'rating', u'votes', u'languages', u'producer', u'mpaa',\n",
       "       u'writer', u'top 250 rank', u'countries', u'aspect_ratio',\n",
       "       u'production companies', u'cinematographer', u'plot outline', u'plot',\n",
       "       u'cast', u'animation department', u'original music',\n",
       "       u'editorial department', u'mpaa_reason', u'revenue_TMDB',\n",
       "       u'overview_TMDB', u'tagline_TMDB', u'vote_count_TMDB',\n",
       "       u'belongs_to_collection_TMDB', u'original_language_TMDB',\n",
       "       u'status_TMDB', u'release_date_TMDB', u'popularity_TMDB',\n",
       "       u'budget_TMDB', u'vote_average_TMDB', u'runtime_TMDB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = generate_train_test_data(x_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 9)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train.to_csv(\"x_train.csv\")\n",
    "x_test.to_csv(\"x_test.csv\")\n",
    "y_train.to_csv(\"y_train.csv\")\n",
    "y_test.to_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run functions in the supplement before running this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Function to generate train and test data for classification models #######\n",
    "### ------ Input ---------- ###\n",
    "# feature_data: a data frame with original features from IMDB and TMDB\n",
    "# genre_data: a data grame with genres (already merged turned into one-hot coding), \n",
    "#             matching the feature_data by 'imdb_ids'\n",
    "# n_sample: the number of data points to sample from the input data frame to fit model\n",
    "# train_ratio: the percentage of training data among sampled data\n",
    "# ran_state: seed for random sampling\n",
    "\n",
    "\n",
    "def generate_train_test_data(x_full, y_full):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    import random\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------ #     \n",
    "    \n",
    "    ### split into train and test data ###\n",
    "    \n",
    "    x_train = x_full[:3000]\n",
    "    x_test = x_full[3000:]\n",
    "    y_train = y_full[:3000]\n",
    "    y_test = y_full[3000:]\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------ # \n",
    "    ### Variable Group 1: ['year', 'rating', 'votes', 'popularity_TMDB', 'runtime_TMDB'] ###\n",
    "\n",
    "    val_group1 = ['year', 'rating', 'votes', 'popularity_TMDB', 'runtime_TMDB']\n",
    "    \n",
    "    ## missing value imputation ##\n",
    "    # use the mean from train data to fill test data \n",
    "\n",
    "    # 'year', 'rating', 'votes' have missing values as 'NaN', fill by column mean\n",
    "    x_train.ix[x_train['year'].isnull(), 'year'] = x_train['year'].mean()\n",
    "    x_test.ix[x_test['year'].isnull(), 'year'] = x_train['year'].mean()\n",
    "\n",
    "    x_train.ix[x_train['rating'].isnull(), 'rating'] = x_train['rating'].mean()\n",
    "    x_test.ix[x_test['rating'].isnull(), 'rating'] = x_train['rating'].mean()\n",
    "\n",
    "    x_train.ix[x_train['votes'].isnull(), 'votes'] = x_train['votes'].mean()\n",
    "    x_test.ix[x_test['votes'].isnull(), 'votes'] = x_train['votes'].mean()\n",
    "\n",
    "    # 'popularity_TMDB' have missing values as 0, replace by column mean\n",
    "    x_train.ix[x_train['popularity_TMDB'] == 0, 'popularity_TMDB'] = x_train['popularity_TMDB'].mean()\n",
    "    x_test.ix[x_test['popularity_TMDB'] == 0, 'popularity_TMDB'] = x_train['popularity_TMDB'].mean()\n",
    "    \n",
    "    # 'runtime_TMDB' have missing values as 0 and 'NaN'\n",
    "    value = x_train['runtime_TMDB'].mean()\n",
    "    x_train.ix[x_train['runtime_TMDB'] == 0, 'runtime_TMDB'] = value\n",
    "    x_train.ix[x_train['runtime_TMDB'].isnull(), 'runtime_TMDB'] = value\n",
    "    x_test.ix[x_test['runtime_TMDB'] == 0, 'runtime_TMDB'] = value\n",
    "    x_test.ix[x_test['runtime_TMDB'].isnull(), 'runtime_TMDB'] = value\n",
    "    \n",
    "    \n",
    "    ## use x_train_new, x_test_new to record the transformed data\n",
    "    x_train_group1 = x_train[val_group1]\n",
    "    x_test_group1 = x_test[val_group1]\n",
    "\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------ # \n",
    "    ### Variables Group 2: ['title', 'plot', 'plot outline', 'overview_TMDB', 'tagline_TMDB', 'mpaa_reason'] ###\n",
    "\n",
    "    ## combine the text in ['title', 'plot', 'plot outline', 'overview_TMDB', 'tagline_TMDB']\n",
    "\n",
    "#     x_train_text = x_train['title'].str.cat([x_train['plot'], x_train['plot outline'], \n",
    "#                               x_train['overview_TMDB'], x_train['tagline_TMDB']], \n",
    "#                               na_rep = \" \")\n",
    "#     x_train_text = pd.DataFrame(x_train_text, index = x_train.index)\n",
    "\n",
    "#     x_test_text = x_test['title'].str.cat([x_test['plot'], x_train['plot outline'], \n",
    "#                               x_test['overview_TMDB'], x_test['tagline_TMDB']], \n",
    "#                               na_rep = \" \")\n",
    "#     x_test_text = pd.DataFrame(x_test_text, index = x_test.index)\n",
    "\n",
    "#     ## apply text analysis on combined text and return the top 30 PCs\n",
    "#     x_train_group2, x_test_group2 = text_analysis(x_train_text, x_test_text,\n",
    "#                                              val_name = 'text', n_components = 30)\n",
    "\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------ # \n",
    "    ### Variables Group 3: [mpaa_reason'] ###\n",
    "\n",
    "    ## apply text analysis on 'mpaa_reason' and return thr PCs that cover 60% variance\n",
    "    x_train_mpaa = pd.DataFrame(x_train['mpaa_reason'], index = x_train.index)\n",
    "    x_test_mpaa = pd.DataFrame(x_test['mpaa_reason'], index = x_test.index)\n",
    "    \n",
    "    x_train_group3, x_test_group3 = text_analysis(x_train_mpaa, x_test_mpaa,\n",
    "                                             val_name = 'mpaa', n_components = 10)\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------ # \n",
    "    ### Variables Group 4: ['director', 'cast', 'production company', 'writer'] ###\n",
    "    \n",
    "    x_train_group4_1, x_test_group4_1 = top_features(train_feature = x_train, train_genre = y_train,\n",
    "                                        test_feature = x_test, test_genre = y_test,\n",
    "                                        val_name = 'director',\n",
    "                                        val_n = 1)\n",
    "    \n",
    "    x_train_group4_2, x_test_group4_2 = top_features(train_feature = x_train, train_genre = y_train,\n",
    "                                        test_feature = x_test, test_genre = y_test,\n",
    "                                        val_name = 'writer',\n",
    "                                        val_n = 1)\n",
    "\n",
    "    x_train_group4_3, x_test_group4_3 = top_features_pca(train_feature = x_train, train_genre = y_train,\n",
    "                                        test_feature = x_test, test_genre = y_test,\n",
    "                                         val_name = 'cast',\n",
    "                                         val_n = 5,\n",
    "                                         pca_n = 10)\n",
    "\n",
    "    x_train_group4_4, x_test_group4_4 = top_features_pca(train_feature = x_train, train_genre = y_train,\n",
    "                                        test_feature = x_test, test_genre = y_test,\n",
    "                                         val_name = 'production companies',\n",
    "                                         val_n = 5,\n",
    "                                         pca_n = 5)\n",
    "     \n",
    "    x_train_group4 = pd.concat([x_train_group4_1, x_train_group4_2,\n",
    "                               x_train_group4_3, x_train_group4_4], axis = 1)\n",
    "    x_test_group4 = pd.concat([x_test_group4_1, x_test_group4_2,\n",
    "                               x_test_group4_3, x_test_group4_4], axis = 1)\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------ # \n",
    "    ### Variables Group 5: ['animation department', 'original music'] ###\n",
    "    \n",
    "    # return x_train_group5, x_test_group5\n",
    "    \n",
    "    x_train_group5_1, x_test_group5_1 = feature_to_count(train_feature = x_train, train_genre = y_train,\n",
    "                                        test_feature = x_test, test_genre = y_test,\n",
    "                                        val_name = 'animation department')\n",
    "\n",
    "    x_train_group5_2, x_test_group5_2 = feature_to_count(train_feature = x_train, train_genre = y_train,\n",
    "                                        test_feature = x_test, test_genre = y_test,\n",
    "                                        val_name = 'original music')\n",
    "    \n",
    "    \n",
    "    x_train_group5 = pd.concat([x_train_group5_1, x_train_group5_2], axis = 1)\n",
    "    x_test_group5 = pd.concat([x_test_group5_1, x_test_group5_2], axis = 1)\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------ # \n",
    "    ### Variables Group 6: ['countries'] ###\n",
    "    x_train_country = text_to_matrix(pd.DataFrame(x_train['countries'], index = x_train.index))\n",
    "    x_test_country = text_to_matrix(pd.DataFrame(x_test['countries'], index = x_test.index))\n",
    "    \n",
    "    x_train_country.index = x_train.index\n",
    "    x_test_country.index = x_test.index\n",
    "    \n",
    "      # count the number of countries for each movie\n",
    "    x_train_group6_1 = pd.DataFrame(x_train_country.sum(axis = 1), columns = ['country_n'])\n",
    "    x_test_group6_1 = pd.DataFrame(x_test_country.sum(axis = 1), columns = ['country_n'])\n",
    "    \n",
    "      # keep the information of major countries\n",
    "    country_major = ['usa', 'france', 'uk', 'germany', 'italy', 'canada', 'japan', 'india', 'spain']\n",
    "    x_train_group6_2 = x_train_country[country_major]\n",
    "    x_train_group6_2.columns = ['country_usa', 'country_france', \n",
    "                                 'country_uk', 'country_germany',\n",
    "                                 'country_italy', 'country_canada', \n",
    "                                 'country_japan', 'country_india', 'country_spain'] \n",
    "    x_test_group6_2 = x_test_country[country_major]\n",
    "    x_test_group6_2.columns = ['country_usa', 'country_france', \n",
    "                                 'country_uk', 'country_germany',\n",
    "                                 'country_italy', 'country_canada', \n",
    "                                 'country_japan', 'country_india', 'country_spain']\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------ # \n",
    "    ### Combine Engineered Features ###\n",
    "    x_train_new = pd.concat([x_train_group1, x_train_group3, \n",
    "                             x_train_group4, x_train_group5,\n",
    "                             x_train_group6_1, x_train_group6_2], axis=1)\n",
    "    \n",
    "    x_test_new = pd.concat([x_test_group1, x_test_group3, \n",
    "                             x_test_group4, x_test_group5,\n",
    "                            x_test_group6_1, x_test_group6_2], axis=1)\n",
    "     \n",
    "    return (x_train_new, x_test_new, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplement: functions that are used in the above meta-function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### part of the function to apply text analysis to a data series #####\n",
    "#### to transform a text paragraph to bag-of-words than to one-hot coding\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "### Input ###\n",
    "        # data: a series for text analysis\n",
    "\n",
    "        \n",
    "### Output ###\n",
    "        # the transformed data in one-hot coding\n",
    "#----------------------------------------------------------------------------------------------------        \n",
    "\n",
    "\n",
    "\n",
    "def text_to_matrix(data):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## --------------- Bag-of-Words --------------- ##\n",
    "    \n",
    "    ## string to list\n",
    "    import re\n",
    "    col_words = []\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "    \n",
    "        if type(data.iloc[i,0]) == str: \n",
    "            letters_only = re.sub(\"[^a-zA-Z]\", \" \" , data.iloc[i,0]) # remove non-letter\n",
    "            lower_case = letters_only.lower().split()   # Convert to lower case # Split into words\n",
    "            \n",
    "            # avoid downloading nltk\n",
    "            # from NLTK stopwords https://pythonprogramming.net/stop-words-nltk-tutorial/\n",
    "            stops = {'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', \n",
    "                     'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', \n",
    "                     'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', \n",
    "                     's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', \n",
    "                     'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', \n",
    "                     'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', \n",
    "                     'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', \n",
    "                     'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', \n",
    "                     'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', \n",
    "                     'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', \n",
    "                     'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', \n",
    "                     'it', 'how', 'further', 'was', 'here', 'than'} \n",
    "            meaningful_words = [w for w in lower_case if not w in stops]  # Remove stop words from \"words\"\n",
    "            \n",
    "            words = ( \" \".join(meaningful_words))\n",
    "    \n",
    "        else: words = \"NA\"\n",
    "       \n",
    "        col_words.append(words)\n",
    "        \n",
    "        \n",
    "    \n",
    "    ## list to vector\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    # Initialize the \"CountVectorizer\" object\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                                 tokenizer = None,    \n",
    "                                 preprocessor = None, \n",
    "                                 stop_words = None,   \n",
    "                                 max_features = 20000)\n",
    "\n",
    "    data_array = vectorizer.fit_transform(col_words)\n",
    "    data_array = pd.DataFrame(data_array.toarray())\n",
    "    data_array.columns = vectorizer.get_feature_names()\n",
    "    \n",
    "    return data_array\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Variable ['title', 'plot', 'plot outline', 'overview_TMDB', 'tagline_TMDB', 'mpaa_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Function to apply text analysis to a column with `colname` in the data file `filename`\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "### Input ###\n",
    "        # train: the train data in one-hot coding\n",
    "        # test: the test data in one-hot coding\n",
    "        # val_name:  variable name that's used in naming the columns as \"val_name_PCi\"\n",
    "        # n_components: if value is int, the number of PCs to return\n",
    "                       # if value between (0,1), the variance explained by the PCs returnd\n",
    "        \n",
    "### Output ###\n",
    "        # data matrix of engineered feature, one for train data and one for test data\n",
    "#----------------------------------------------------------------------------------------------------        \n",
    "\n",
    "\n",
    "def text_analysis(train, test, val_name, n_components):\n",
    "    \n",
    "    ## turn each text paragraph into one-hot coding\n",
    "    train_array = text_to_matrix(train)\n",
    "    test_array = text_to_matrix(test)\n",
    "    \n",
    "    ## take the union set of words in train and text data as column\n",
    "    ## words that don't show up are assigned 0\n",
    "    align_column = pd.concat([train_array,test_array], axis=0).fillna(0)\n",
    "    # keep only the gas-of-words from training data\n",
    "    align_column = align_column[train_array.columns]\n",
    "    \n",
    "    ## split into train and text after aligning the columns\n",
    "    train_array = align_column.iloc[0:train_array.shape[0], ]\n",
    "    test_array = align_column.iloc[train_array.shape[0]:, ]\n",
    "    \n",
    "    ## PCA\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components = n_components)\n",
    "    pca.fit(train_array)\n",
    "    train_new = pd.DataFrame(pca.transform(train_array), index = train.index)\n",
    "    test_new = pd.DataFrame(pca.transform(test_array), index = test.index)\n",
    "    test_new = test_new.fillna(value = 0)\n",
    "    \n",
    "    col_names = []\n",
    "    for i in range(train_new.shape[1]):\n",
    "        i_name = val_name + \"_PC\" + str(i+1)\n",
    "        col_names.append(i_name)\n",
    "        \n",
    "    train_new.columns = col_names\n",
    "    test_new.columns = col_names\n",
    "    \n",
    "    return (train_new, test_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function used in the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function to convert to string list [u'Action', u'Adventure', u'Fantasy'] into dummy coding\n",
    "## input: \n",
    "           # data = orignal data frame, \n",
    "           # val_name = name of the variable\n",
    "## output: a data frame\n",
    "\n",
    "def string_to_vector(data, val_name):\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    \n",
    "    # convert any np.nan to a string 'nan'\n",
    "    data[val_name][pd.isnull(data[val_name])] = 'nan'\n",
    "    \n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                                             tokenizer = None,    \n",
    "                                             preprocessor = None, \n",
    "                                             stop_words = None,   \n",
    "                                             max_features = 50000)\n",
    "\n",
    "    val_data = vectorizer.fit_transform(data[val_name])\n",
    "    df_val = pd.DataFrame(val_data.toarray())\n",
    "    df_val.columns = vectorizer.get_feature_names()\n",
    "    df_val.index = data.index\n",
    "    \n",
    "    return df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Variable ['director', 'writer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function considers a particular feature of interest (e.g. director, writer) \n",
    "### and picks out the top val_n most important value in each genre\n",
    "### Input: \n",
    "# - train_feature: df with 2500 train observations, all feature columns, indexed with imdb_ids\n",
    "# - train_genre: df with 2500 train observations, all genre columns, indexed with imdb_ids\n",
    "# - test_feature: df with 2500 test observations, all feature columns, indexed with imdb_ids \n",
    "# - test_genre: df with 2500 test observations, all genre columns, indexed with imdb_ids\n",
    "# - val_name # feature of interest, eg. director\n",
    "# - val_n # number of top values to take, eg. 1\n",
    "### Output:\n",
    "# - train_val: df with 2500 train observations, new columns of top directors, indexed with imdb_ids\n",
    "# - test_val: df with 2500 test observations, new columns of top directors, indexed with imdb_ids\n",
    "\n",
    "def top_features(train_feature, train_genre, test_feature, test_genre,\n",
    "                val_name = 'director', val_n = 1):\n",
    "\n",
    "    # convert feature of interest into dummy variables in train set and test set\n",
    "    feature_val_train = string_to_vector(train_feature, val_name)\n",
    "    feature_val_test = string_to_vector(test_feature, val_name)\n",
    "\n",
    "    # create a dataframe with columns consisting of all directors and all genres, rows are movie entries \n",
    "    feature_val_genre = pd.concat([feature_val_train, train_genre], axis = 1)\n",
    "    \n",
    "    # generate list of top directors in each genre \n",
    "    val_list = []\n",
    "    for i in train_genre.columns:\n",
    "        sum_val_in_genre = feature_val_genre.ix[feature_val_genre[i] == 1, range(feature_val_train.shape[1]-1)].sum(axis = 0)\n",
    "        sum_val_in_genre_sorted = sum_val_in_genre.sort(inplace=False, ascending = False)\n",
    "        for j in range(val_n):\n",
    "            top_val_in_genre = sum_val_in_genre_sorted.index[j]\n",
    "            val_list.append(top_val_in_genre)      \n",
    "\n",
    "    # output dataframes of movies with new columns\n",
    "    train_val = feature_val_train.ix[:, val_list] \n",
    "    test_val = feature_val_test.ix[:, val_list]\n",
    "    \n",
    "    # replace any NA vaalues in the test set with 0\n",
    "    test_val = test_val.fillna(value = 0)\n",
    "    \n",
    "    # rename columns as director1, director2, etc\n",
    "    col_names = []\n",
    "    for i in range(train_val.shape[1]):\n",
    "            i_name = val_name + str(i)\n",
    "            col_names.append(i_name)\n",
    "    train_val.columns = col_names\n",
    "    test_val.columns = col_names\n",
    "\n",
    "    return(train_val, test_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Variable ['cast','production company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function considers a particular feature of interest (e.g. cast, production companies) \n",
    "### and picks out the top val_n most important value in each genre\n",
    "### and then performs PCA, picks out the top pca_n numbers of components\n",
    "### Input: \n",
    "# - train_feature: df with 2500 train observations, all feature columns, indexed with imdb_ids\n",
    "# - train_genre: df with 2500 train observations, all genre columns, indexed with imdb_ids\n",
    "# - test_feature: df with 2500 test observations, all feature columns, indexed with imdb_ids \n",
    "# - test_genre: df with 2500 test observations, all genre columns, indexed with imdb_ids\n",
    "# - val_name # feature of interest, eg. director\n",
    "# - val_n # number of top values to take, eg. 5\n",
    "# - pca_n # number of pca components to retain, eg. 5\n",
    "### Output:\n",
    "# - train_val: df with 3000 train observations, columns as pca components, indexed with imdb_ids\n",
    "# - test_val: df with 2000 test observations, columns as pca components, indexed with imdb_ids\n",
    "\n",
    "def top_features_pca(train_feature, train_genre, test_feature, test_genre,\n",
    "                     val_name = 'cast',\n",
    "                     val_n = 5,\n",
    "                     pca_n = 5):\n",
    "    \n",
    "    ## Step 1, pick top casts in each genre using top_feature function \n",
    "    train_val, test_val = top_features(train_feature = train_feature,\n",
    "                    train_genre = train_genre,\n",
    "                    test_feature = test_feature,\n",
    "                    test_genre = test_genre,\n",
    "                    val_name = val_name,\n",
    "                    val_n = val_n)\n",
    "    \n",
    "    # replace any NA values in test set with 0 (or will have problem in pca.transform)\n",
    "    test_val = test_val.fillna(value=0)\n",
    "\n",
    "    ## Step 2, perform PCA\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    pca = PCA(n_components = pca_n, svd_solver = \"full\") # keep the first pca_n PCs\n",
    "    pca = pca.fit(train_val)\n",
    "    train_pca = pd.DataFrame(pca.transform(train_val), index = train_val.index)\n",
    "    test_pca = pd.DataFrame(pca.transform(test_val), index = test_val.index)\n",
    "\n",
    "    ## Step 3, rename the columns as cast_PC1, cast_PC2, etc. \n",
    "    col_names = []\n",
    "    for i in range(pca_n):\n",
    "            i_name = val_name + \"_PC\" + str(i+1)\n",
    "            col_names.append(i_name)\n",
    "    train_pca.columns = col_names\n",
    "    test_pca.columns = col_names\n",
    "\n",
    "    return (train_pca, test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Variable ['animatino department', 'original music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function considers a particular feature of interest (e.g. animation department, original music) \n",
    "### and counts the number of member occurance in each movie \n",
    "### Input: \n",
    "# - train_feature: df with 2500 train observations, all feature columns, indexed with imdb_ids\n",
    "# - test_feature: df with 2500 test observations, all feature columns, indexed with imdb_ids \n",
    "# - val_name # feature of interest, eg. animation department\n",
    "### Output:\n",
    "# - train_count: df with 2500 train observations, new column of count, indexed with imdb_ids\n",
    "# - test_count: df with 2500 test observations, new column of count, indexed with imdb_ids\n",
    "\n",
    "def feature_to_count(train_feature, train_genre, test_feature, test_genre,\n",
    "                val_name = 'animation department'):\n",
    "    \n",
    "    # convert column to number of counts of members \n",
    "    train_count = pd.DataFrame(string_to_vector(train_feature, val_name).ix[:,:-1].sum(axis=1), \n",
    "                               columns = {val_name + ' count'})\n",
    "    test_count = pd.DataFrame(string_to_vector(test_feature, val_name).ix[:,:-1].sum(axis=1), \n",
    "                              columns = {val_name + ' count'})\n",
    "    \n",
    "    return(train_count, test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2. Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "\n",
    "We considered three metircs to use:\n",
    "\n",
    "#### F1 Score: #### \n",
    "- For each movie to be predicted, we use the `f1_score` function from `sklearn.metrics` package to compare the predicted value (23-long vector with 0 and 1 for each genre) and true value. To start with, we can calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "- We choose F1 score because we care about both false positive and false negative mistakes. For now we are giving them the same weights, so we take the harmonic mean of precision and recall. But this can be further adjusted depending on the application of this prediction (whether it's worse to mis-classified a genre or to miss a genre).\n",
    "\n",
    "#### weighted F1 Score: #### \n",
    "- We can also use the 'weighted average' for F1 score: calculate metrics for each label, and find their average, weighted by support (the number of true instances for each label). This accounts for inbalanced data.\n",
    "\n",
    "#### IoU Score ####\n",
    "- We also exlored another metric: Intersection over Union (IoU). Accuracy score here is defined as (intersection between real and predicted vectors) / (union between real and predicted vectors). It also moniters both false positive and false negtive mistakes.\n",
    "\n",
    "For the following model tuning, we'll use unweighted F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function to calculate averaged F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function f1_genre\n",
    "# input: two pandas dataframes, \n",
    "    # genre_real: predicted values\n",
    "    # genre_predict: real values\n",
    "# output: mean f1 score of each class\n",
    "def f1_genres(genre_real, genre_predict):\n",
    "    count_row = len(genre_real)\n",
    "    if count_row == 0:\n",
    "        print \"No data in dataframe!\"\n",
    "        return\n",
    "    if count_row != len(genre_predict):\n",
    "        print \"Different length of predicted and real dataframes!\"\n",
    "        return\n",
    "    count_col = len(genre_real.columns)\n",
    "    if count_col == 0:\n",
    "        print \"No data in dataframe!\"\n",
    "        return\n",
    "    if count_col != len(genre_predict.columns):\n",
    "        print \"Different genres of predicted and real dataframes!\"\n",
    "        return\n",
    "    score = 0\n",
    "    for i in range(count_col):\n",
    "        score += f1_score(genre_real[genre_real.columns.values[i]], genre_predict[genre_predict.columns.values[i]])\n",
    "    score = score/count_col\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate the aveage IoU score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function score_genre\n",
    "# input: two pandas dataframes, \n",
    "    # genre_real: predicted values\n",
    "    # genre_predict: real values\n",
    "# output: mean accuracy of prediction\n",
    "# accuracy score here is defined as \n",
    "    # (intersection between real and predicted vectors) / (union between real and predicted vectors)\n",
    "\n",
    "def score_genre(genre_real, genre_predict):\n",
    "    count_row = len(genre_real)\n",
    "    if count_row == 0:\n",
    "        print \"No data in dataframe!\"\n",
    "        return\n",
    "    if count_row != len(genre_predict):\n",
    "        print \"Different length of predicted and real dataframes!\"\n",
    "        return\n",
    "    count_col = len(genre_real.columns)\n",
    "    if count_col == 0:\n",
    "        print \"No data in dataframe!\"\n",
    "        return\n",
    "    if count_col != len(genre_predict.columns):\n",
    "        print \"Different genres of predicted and real dataframes!\"\n",
    "        return\n",
    "    accuracy_genre = 0.0\n",
    "    for i in range(count_row):\n",
    "        count_intersection = 0.0\n",
    "        count_unity = 0.0\n",
    "        accuracy_temp = 0.0\n",
    "        for j in range(len(genre_real.columns)):\n",
    "            if genre_real.iloc[i][j] == 1 or genre_predict.iloc[i][j] == 1:\n",
    "                count_unity += 1.0\n",
    "            if genre_real.iloc[i][j] == 1 and genre_predict.iloc[i][j] == 1:\n",
    "                count_intersection += 1.0 \n",
    "        if count_unity == 0: # a few ovservations has no genre assigned, delete these values from evaluation\n",
    "            count_row = count_row - 1\n",
    "        else:\n",
    "            accuracy_temp = count_intersection / count_unity\n",
    "            accuracy_genre += accuracy_temp\n",
    "    if count_row <= 0:\n",
    "        print \"No meaning value!\"\n",
    "        return\n",
    "    return (accuracy_genre/count_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3. Benchmark Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import scipy as sp\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in datasets\n",
    "x_test = pd.read_csv('x_test.csv',index_col=0)\n",
    "x_train = pd.read_csv('x_train.csv',index_col=0)\n",
    "y_test = pd.read_csv('y_test.csv',index_col=0)\n",
    "y_train = pd.read_csv('y_train.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>popularity_TMDB</th>\n",
       "      <th>runtime_TMDB</th>\n",
       "      <th>mpaa_PC1</th>\n",
       "      <th>mpaa_PC2</th>\n",
       "      <th>mpaa_PC3</th>\n",
       "      <th>mpaa_PC4</th>\n",
       "      <th>mpaa_PC5</th>\n",
       "      <th>...</th>\n",
       "      <th>country_n</th>\n",
       "      <th>country_usa</th>\n",
       "      <th>country_france</th>\n",
       "      <th>country_uk</th>\n",
       "      <th>country_germany</th>\n",
       "      <th>country_italy</th>\n",
       "      <th>country_canada</th>\n",
       "      <th>country_japan</th>\n",
       "      <th>country_india</th>\n",
       "      <th>country_spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1982.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-0.266757</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>-0.020917</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.033750</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>-0.266757</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>-0.020917</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>-0.266757</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>-0.020917</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>87.957095</td>\n",
       "      <td>-0.266757</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>-0.020917</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1968.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.266757</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>-0.020917</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  rating  votes  popularity_TMDB  runtime_TMDB  mpaa_PC1  mpaa_PC2  \\\n",
       "0  1982.0     7.8   15.0         0.000008     60.000000 -0.266757  0.003165   \n",
       "1  1987.0     7.4    9.0         0.033750     75.000000 -0.266757  0.003165   \n",
       "2  2010.0     2.5  127.0         0.000715     92.000000 -0.266757  0.003165   \n",
       "3  2007.0     6.9   12.0         0.001205     87.957095 -0.266757  0.003165   \n",
       "4  1968.0     6.6   13.0         0.000215      5.000000 -0.266757  0.003165   \n",
       "\n",
       "   mpaa_PC3  mpaa_PC4  mpaa_PC5      ...        country_n  country_usa  \\\n",
       "0 -0.020917 -0.003125 -0.002995      ...                1            0   \n",
       "1 -0.020917 -0.003125 -0.002995      ...                1            1   \n",
       "2 -0.020917 -0.003125 -0.002995      ...                1            1   \n",
       "3 -0.020917 -0.003125 -0.002995      ...                1            0   \n",
       "4 -0.020917 -0.003125 -0.002995      ...                1            0   \n",
       "\n",
       "   country_france  country_uk  country_germany  country_italy  country_canada  \\\n",
       "0               0           1                0              0               0   \n",
       "1               0           0                0              0               0   \n",
       "2               0           0                0              0               0   \n",
       "3               1           0                0              0               0   \n",
       "4               1           0                0              0               0   \n",
       "\n",
       "   country_japan  country_india  country_spain  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Act_Adven_West</th>\n",
       "      <th>Mus_Bio_His_War_Doc</th>\n",
       "      <th>Sh_Ani_Fam</th>\n",
       "      <th>Fant_SF</th>\n",
       "      <th>Mys_Cri_Hor_Thr</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Comedy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220440</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1686303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1103253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459149</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Act_Adven_West  Mus_Bio_His_War_Doc  Sh_Ani_Fam  Fant_SF  \\\n",
       "0        220440               0                    1           0        0   \n",
       "1        136227               0                    0           0        0   \n",
       "2       1686303               0                    0           0        0   \n",
       "3       1103253               0                    0           0        0   \n",
       "4        459149               1                    0           1        0   \n",
       "\n",
       "   Mys_Cri_Hor_Thr  Romance  Drama  Comedy  \n",
       "0                0        0      0       0  \n",
       "1                0        0      0       0  \n",
       "2                1        0      0       1  \n",
       "3                0        0      1       0  \n",
       "4                0        0      1       0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### standardize\n",
    "scaler = preprocessing .StandardScaler().fit(x_train)\n",
    "x_train_np = scaler.transform(x_train)\n",
    "x_test_np = scaler.transform(x_test)\n",
    "\n",
    "indexs_train = x_train.index\n",
    "indexs_test = x_test.index\n",
    "x_train = pd.DataFrame(x_train_np, index = indexs_train, columns = x_train.columns)\n",
    "x_test = pd.DataFrame(x_test_np, index = indexs_test, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Baseline Model\n",
    "We'll quickly go through classification models without feature selection or model tuning, and have a sense of their base peformance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### methods support multilabel classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-22c524c1da5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mscore_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_genres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"F1 Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_knn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3847072597c2>\u001b[0m in \u001b[0;36mf1_genres\u001b[0;34m(genre_real, genre_predict)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_real\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    690\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    691\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1018\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1019\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "random.seed(0)\n",
    "knn = KNN(n_neighbors=1)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "y_pred= pd.DataFrame(y_pred, columns = y_test.columns.values)\n",
    "\n",
    "score_knn = f1_genres(y_test, y_pred)\n",
    "print \"F1 Score:\", score_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-b1a26bbbc725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscore_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_genres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"F1 Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3847072597c2>\u001b[0m in \u001b[0;36mf1_genres\u001b[0;34m(genre_real, genre_predict)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_real\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    690\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    691\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1018\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1019\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "random.seed(0)\n",
    "tree = DecisionTree(max_depth=6)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(x_test)\n",
    "y_pred= pd.DataFrame(y_pred, columns = y_test.columns.values)\n",
    "\n",
    "score_tree = f1_genres(y_test, y_pred)\n",
    "print \"F1 Score:\", score_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-71cde57b2223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscore_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_genres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"F1 Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_rf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3847072597c2>\u001b[0m in \u001b[0;36mf1_genres\u001b[0;34m(genre_real, genre_predict)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_real\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    690\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    691\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1018\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1019\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random.seed(0)\n",
    "rf = RandomForest()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(x_test)\n",
    "y_pred= pd.DataFrame(y_pred, columns = y_test.columns.values)\n",
    "\n",
    "score_rf = f1_genres(y_test, y_pred)\n",
    "print \"F1 Score:\", score_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other classifiers that don't support multilabel classification, thus need to fit classifier for each genre, then combine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-be1c77703d7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgenre_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0munweighted_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mscore_unweighted_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_genres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"F1 Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_unweighted_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3847072597c2>\u001b[0m in \u001b[0;36mf1_genres\u001b[0;34m(genre_real, genre_predict)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_real\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    690\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    691\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1018\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1019\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "# Unweighted logistic regression\n",
    "random.seed(0)\n",
    "\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    unweighted_logistic = LogisticRegression()\n",
    "    unweighted_logistic.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= unweighted_logistic.predict(x_test)\n",
    "\n",
    "score_unweighted_log = f1_genres(y_test, y_pred)\n",
    "print \"F1 Score:\", score_unweighted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.136608687734\n"
     ]
    }
   ],
   "source": [
    "# weighted logistic regression\n",
    "random.seed(0)\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "    weighted_logistic.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= weighted_logistic.predict(x_test)\n",
    "\n",
    "score_weighted_log = f1_genres(y_test, y_pred)\n",
    "print \"F1 Score:\", score_weighted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.136608687734\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "random.seed(0)\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    lda = LDA()\n",
    "    lda.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= lda.predict(x_test)\n",
    "\n",
    "score_lda = f1_genres(y_test, y_pred)\n",
    "print \"F1 Score:\", score_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.136608687734\n"
     ]
    }
   ],
   "source": [
    "#QDA\n",
    "random.seed(0)\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    qda = QDA()\n",
    "    qda.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= qda.predict(x_test)\n",
    "\n",
    "score_qda = f1_genres(y_test, y_pred)\n",
    "print \"F1 Score:\", score_qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.136608687734\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "random.seed(0)\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    svm = SVC(C=5, class_weight='balanced')\n",
    "    svm.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= svm.predict(x_test)\n",
    "\n",
    "score_svm = f1_genres(y_test, y_pred)\n",
    "print \"F1 Score:\", score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>lda</th>\n",
       "      <th>qda</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "      <th>unweighted logistic</th>\n",
       "      <th>weighted logistic</th>\n",
       "      <th>weighted svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.171634</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.136609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_f1_score</th>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.171634</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>0.136609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      knn       lda       qda        rf      tree  \\\n",
       "f1_score           0.2735  0.136609  0.136609  0.136609  0.171634   \n",
       "weighted_f1_score  0.2735  0.136609  0.136609  0.136609  0.171634   \n",
       "\n",
       "                   unweighted logistic  weighted logistic  weighted svm  \n",
       "f1_score                      0.136609           0.136609      0.136609  \n",
       "weighted_f1_score             0.136609           0.136609      0.136609  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({'knn': score_knn, \n",
    "                         'tree': score_tree,\n",
    "                         'rf': score_rf,\n",
    "                         'unweighted logistic': score_unweighted_log,\n",
    "                         'weighted logistic': score_weighted_log,\n",
    "                         'lda': score_lda,\n",
    "                         'qda': score_qda,                        \n",
    "                         'weighted svm': score_svm}, index = ['f1_score', 'weighted_f1_score'])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10a1d2fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFRCAYAAACPNe3VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4iEkMJdRCSEFO4iIiGkcBcRCaH/B98HSl1XCGOeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109015a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df.plot(kind = \"bar\")\n",
    "plt.title(\"Model Score for Un-tuned Baseline Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without feature selection or model tuning, we found that weighted logistic regression gives the best score. Although both random forest and SVM are both very sensitive to model tuning and have space for improvement.\n",
    "\n",
    "Next, we are going to tune the follwoing three models:\n",
    "- Weighted Logistic Regression\n",
    "- RF\n",
    "- SVM\n",
    "\n",
    "We'll also perform feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Weighted Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b7772f4c303e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_weighted_log_tune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Best C:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_weighted_log_tune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "c_best = c[np.argmax(score_weighted_log_tune)]\n",
    "print 'Best C:', c_best\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(c, score_weighted_log_tune)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Tuning weighted logistic regression: C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of tuned Weighted Logistic Regression: 0.383416268959\n"
     ]
    }
   ],
   "source": [
    "# weighted logistic regression\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    weighted_logistic = LogisticRegression(class_weight='balanced', C = c_best)\n",
    "    weighted_logistic.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= weighted_logistic.predict(x_test)\n",
    "\n",
    "score_weighted_log = f1_genres(y_test, genre_pred)\n",
    "print \"F1 Score of tuned Weighted Logistic Regression:\", score_weighted_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also want to tune the parameter C for each columns to optimize its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 0.001\n",
      "Adventure 1e-05\n",
      "Comedy 0.1\n",
      "Crime 0.0001\n",
      "Fantasy 0.1\n",
      "Family 0.0001\n",
      "Romance 1e-05\n",
      "Horror 0.0001\n",
      "Western 0.0001\n",
      "Documentary 0.01\n",
      "Biography 1e-05\n",
      "Drama 0.001\n",
      "Animation 1e-05\n",
      "Sci-Fi 0.1\n",
      "Thriller 0.0001\n",
      "Short 1e-06\n",
      "Mystery 1e-05\n",
      "Sport 0.01\n",
      "War 1e-05\n",
      "History 0.01\n",
      "Music 0.001\n",
      "Foreign 0.001\n",
      "Other 1e-05\n",
      "0.31695870521\n"
     ]
    }
   ],
   "source": [
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    k_cv = 5\n",
    "    score_cv = []\n",
    "    for i in range(-6, 7, 2):\n",
    "        # fit regularized logistic regression model on training set      \n",
    "        weighted_logistic = LogisticRegression(class_weight='balanced', C = 10**i)\n",
    "        score_cv += [sum(cross_val_score(weighted_logistic, x_train, y_train[col], cv = k_cv, scoring = F_score_cv)) / k_cv]\n",
    "    # find best score and corresponding tuning parameter\n",
    "    max_value = max(score_cv)\n",
    "    max_index = score_cv.index(max_value)\n",
    "    C_best = 10**(max_index -7)\n",
    "    print col, C_best\n",
    "    weighted_logistic = LogisticRegression(class_weight='balanced',  C = C_best)\n",
    "    weighted_logistic.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= weighted_logistic.predict(x_test)\n",
    "\n",
    "score_weighted_log = f1_genres(y_test, genre_pred)\n",
    "print score_weighted_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions used in tuning logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function F_score takes model, predictors X and true y values and returns f1_score\n",
    "# this function is modified to suit cross validation format\n",
    "\n",
    "def F_score_cv(model, X, y_true):\n",
    "    y_predict = model.predict(X)\n",
    "    score = f1_score(y_predict, y_true)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TUNING LOGISTIC REGRESSION #####\n",
    "#### parameter c (without cross validation)\n",
    "c = [1, 10, 50, 100, 500, 1000]\n",
    "score_weighted_log_tune = np.zeros(len(c))\n",
    "random.seed(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.4, random_state=0)\n",
    "\n",
    "for i in range(len(c)):\n",
    "    #weighted logistic regression\n",
    "    genre_pred = pd.DataFrame(index = X_test.index) # dataframe to store predicted values of train\n",
    "\n",
    "    for col in y_train.columns:\n",
    "        weighted_logistic = LogisticRegression(class_weight='balanced', C=c[i])\n",
    "        weighted_logistic.fit(X_train, Y_train[col])\n",
    "        genre_pred[col]= weighted_logistic.predict(X_test)\n",
    "\n",
    "    score_weighted_log_tune[i] = f1_genres(Y_test, genre_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of random forest model: 0.144091737997\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random.seed(0)\n",
    "rf = RandomForest(n_estimators=100)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "y_pred= pd.DataFrame(y_pred, columns = y_test.columns.values)\n",
    "score_rf = f1_genres(y_test, y_pred)\n",
    "print \"score of random forest model:\",score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_rank = pd.DataFrame({'feature':x_train.columns.values, 'importance':rf.feature_importances_})\n",
    "feature_rank = feature_rank.sort_values(by = 'importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIoAAAJYCAYAAAANNw3rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12505a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_rank.plot(x = 'feature', y = 'importance', kind = 'bar', figsize = (20, 10), use_index = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runtime_TMDB</td>\n",
       "      <td>0.041638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rating</td>\n",
       "      <td>0.037289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text_PC2</td>\n",
       "      <td>0.031434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text_PC5</td>\n",
       "      <td>0.029211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>text_PC8</td>\n",
       "      <td>0.027413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text_PC9</td>\n",
       "      <td>0.027389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>votes</td>\n",
       "      <td>0.024481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>popularity_TMDB</td>\n",
       "      <td>0.024120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>0.023958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text_PC3</td>\n",
       "      <td>0.023744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text_PC10</td>\n",
       "      <td>0.023556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text_PC4</td>\n",
       "      <td>0.023193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text_PC1</td>\n",
       "      <td>0.022982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>text_PC11</td>\n",
       "      <td>0.022884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>text_PC18</td>\n",
       "      <td>0.022207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>text_PC16</td>\n",
       "      <td>0.021354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>text_PC17</td>\n",
       "      <td>0.020994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>text_PC7</td>\n",
       "      <td>0.020929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>text_PC24</td>\n",
       "      <td>0.020887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>text_PC27</td>\n",
       "      <td>0.020711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>text_PC14</td>\n",
       "      <td>0.020671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>text_PC28</td>\n",
       "      <td>0.020515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>text_PC30</td>\n",
       "      <td>0.020316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>text_PC19</td>\n",
       "      <td>0.020193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>text_PC20</td>\n",
       "      <td>0.019966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>text_PC22</td>\n",
       "      <td>0.019948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>text_PC29</td>\n",
       "      <td>0.019845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>text_PC25</td>\n",
       "      <td>0.019681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>text_PC21</td>\n",
       "      <td>0.019593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>text_PC26</td>\n",
       "      <td>0.019555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>text_PC6</td>\n",
       "      <td>0.019450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>text_PC15</td>\n",
       "      <td>0.019440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>text_PC12</td>\n",
       "      <td>0.019417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>animation department count</td>\n",
       "      <td>0.019313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>text_PC13</td>\n",
       "      <td>0.019061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>text_PC23</td>\n",
       "      <td>0.018835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  importance\n",
       "4                  runtime_TMDB    0.041638\n",
       "1                        rating    0.037289\n",
       "6                      text_PC2    0.031434\n",
       "9                      text_PC5    0.029211\n",
       "12                     text_PC8    0.027413\n",
       "13                     text_PC9    0.027389\n",
       "2                         votes    0.024481\n",
       "3               popularity_TMDB    0.024120\n",
       "0                          year    0.023958\n",
       "7                      text_PC3    0.023744\n",
       "14                    text_PC10    0.023556\n",
       "8                      text_PC4    0.023193\n",
       "5                      text_PC1    0.022982\n",
       "15                    text_PC11    0.022884\n",
       "22                    text_PC18    0.022207\n",
       "20                    text_PC16    0.021354\n",
       "21                    text_PC17    0.020994\n",
       "11                     text_PC7    0.020929\n",
       "28                    text_PC24    0.020887\n",
       "31                    text_PC27    0.020711\n",
       "18                    text_PC14    0.020671\n",
       "32                    text_PC28    0.020515\n",
       "34                    text_PC30    0.020316\n",
       "23                    text_PC19    0.020193\n",
       "24                    text_PC20    0.019966\n",
       "26                    text_PC22    0.019948\n",
       "33                    text_PC29    0.019845\n",
       "29                    text_PC25    0.019681\n",
       "25                    text_PC21    0.019593\n",
       "30                    text_PC26    0.019555\n",
       "10                     text_PC6    0.019450\n",
       "19                    text_PC15    0.019440\n",
       "16                    text_PC12    0.019417\n",
       "106  animation department count    0.019313\n",
       "17                    text_PC13    0.019061\n",
       "27                    text_PC23    0.018835"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_rank[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acoording to the feature importance, take the first 35 features to train the random forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_select = feature_rank.ix[:36, 'feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score after feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of random forest model: 0.161006388284\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random.seed(0)\n",
    "rf = RandomForest(n_estimators=200)\n",
    "rf.fit(x_train[feature_select], y_train)\n",
    "y_pred = rf.predict(x_test[feature_select])\n",
    "y_pred= pd.DataFrame(y_pred, columns = y_test.columns.values)\n",
    "score_rf = f1_genres(y_test, y_pred)\n",
    "print \"score of random forest model:\",score_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, there doesn't seem to be hugh improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Tuning with all the data\n",
    "\n",
    "## set parameter range for tuning\n",
    "n_tree = 100\n",
    "n_feature = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "n_cv = 5\n",
    "\n",
    "rf_tune = []\n",
    "   \n",
    "for i in range(len(n_feature)):\n",
    "        rf = RandomForest(n_estimators=n_tree, max_features = n_feature[i])\n",
    "        score = sum(cross_val_score(rf, x_train, y_train, cv = n_cv, scoring = 'f1_macro'))/n_cv\n",
    "        rf_tune.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAERCAYAAAC+ZEqyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTEREJGP/H0rng2PnpVF/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126019250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_feature,rf_tune)\n",
    "plt.xlabel('max_feature')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Tuning with selected feature\n",
    "\n",
    "## set parameter range for tuning\n",
    "n_tree = 100\n",
    "n_feature = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "n_cv = 5\n",
    "\n",
    "rf_tune = []\n",
    "   \n",
    "for i in range(len(n_feature)):\n",
    "        rf = RandomForest(n_estimators=n_tree, max_features = n_feature[i])\n",
    "        score = sum(cross_val_score(rf, x_train[feature_select], y_train[feature_select], \n",
    "                                    cv = n_cv, scoring = 'f1_macro'))/n_cv\n",
    "        rf_tune.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126683050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_feature,rf_tune)\n",
    "plt.title('with selected features')\n",
    "plt.xlabel('max_feature')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 1\n",
      "Adventure 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-142486b3cee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# fit regularized logistic regression model on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mscore_cv\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF_score_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk_cv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# find best score and corresponding tuning parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mC_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wdq/my-venv/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "c = range(-7, 7)\n",
    "\n",
    "for col in y_train.columns:\n",
    "    k_cv = 5\n",
    "    score_cv = []\n",
    "    for i in range(len(c)):\n",
    "        # fit regularized logistic regression model on training set      \n",
    "        svm = SVC(C=10**c[i], class_weight='balanced')\n",
    "        score_cv += [sum(cross_val_score(svm, x_train, y_train[col], cv = k_cv, scoring = F_score_cv)) / k_cv]\n",
    "    # find best score and corresponding tuning parameter\n",
    "    C_best = 10**c[np.argmax(score_cv)]\n",
    "    print col, C_best\n",
    "    svm = SVC(class_weight='balanced',  C = C_best)\n",
    "    svm.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= svm.predict(x_test)\n",
    "\n",
    "score_svm = f1_genres(y_test, genre_pred)\n",
    "print score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"svm_result.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score of tuned SVM is: 0.390064260284"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. Detailed description and implementation of two different models. Careful performance evaluations for both models.Visualizations of the metrics for performance evaluation.\n",
    "(please see Part 3 for details in model implementation and evaluation.)\n",
    "- We briely tested KNN, decision tree, random forest, LQA, DQA, SVM and logistic regression models, without model tuning or feature selection. The baseline models in general\n",
    "\n",
    "### Q. Description of your performance metrics\n",
    "(as already be discussed in Part 2)\n",
    "- For each movie to be predicted, we use the `f1_score` function from `sklearn.metrics` package to compare the predicted value (23-long vector with 0 and 1 for each genre) and true value. To evaluate the model, we use the averaged F1 score.\n",
    "- We also exlored another metric: Intersection over Union (IoU). Accuracy score here is defined as (intersection between real and predicted vectors) / (union between real and predicted vectors). It also moniters both false positive and false negtive mistakes.\n",
    "\n",
    "- We choose F1 score because we care about both false positive and false negative mistakes. For now we are giving them the same weights, so we take the harmonic mean of precision and recall. But this can be further adjusted depending on the application of this prediction (whether it's worse to mis-classified a genre or to miss a genre).\n",
    "\n",
    "### Q. Discussion of the differences between the models, their strengths, weaknesses, etc.\n",
    "- The weighted logistic regression model and the SVM model seem to have relatively high F1 score (>0.35), while the other models performs poorly.\n",
    "- The SVM and RF models are computationally expensive, but have larger space to improve (by tuning data). LDA and QDA perform poorply as expected, as much complicated data is less likely to be linearly seperable. The logistic regression is quick and easy to intepretate.\n",
    "\n",
    "### Q. Discussion of the performances you achieved, and how you might be able to improve them in the future\n",
    "- The F1 score of different tranditional ML models are generally low. We may need to do seom feature selection, since the total 118 variables may be too much, especially when we are only training on 2500 data points.\n",
    "- Training the model on a much bigger data set may also help improve (we have 25k data in total).\n",
    "- We may also want ot include the poster information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
