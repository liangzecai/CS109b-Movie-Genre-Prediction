{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhengguo\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "# Use package tmdbsimple to extract data\n",
    "import tmdbsimple as tmdb\n",
    "# use \"!pip install tmdbsimple\" to install\n",
    "tmdb.API_KEY = '302f3815bea132a8bfe0d7301c9065dd'\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "import scipy as sp\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in datasets\n",
    "x_test = pd.read_csv('x_test.csv',index_col=0)\n",
    "x_train = pd.read_csv('x_train.csv',index_col=0)\n",
    "y_test = pd.read_csv('y_test.csv',index_col=0)\n",
    "y_train = pd.read_csv('y_train.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function f1_genre\n",
    "# input: two pandas dataframes, \n",
    "    # genre_real: predicted values\n",
    "    # genre_predict: real values\n",
    "# output: mean f1 score of each class\n",
    "def f1_genres(genre_real, genre_predict):\n",
    "    count_row = len(genre_real)\n",
    "    if count_row == 0:\n",
    "        print \"No data in dataframe!\"\n",
    "        return\n",
    "    if count_row != len(genre_predict):\n",
    "        print \"Different length of predicted and real dataframes!\"\n",
    "        return\n",
    "    count_col = len(genre_real.columns)\n",
    "    if count_col == 0:\n",
    "        print \"No data in dataframe!\"\n",
    "        return\n",
    "    if count_col != len(genre_predict.columns):\n",
    "        print \"Different genres of predicted and real dataframes!\"\n",
    "        return\n",
    "    score = 0\n",
    "    for i in range(count_col):\n",
    "        score += f1_score(genre_real[genre_real.columns.values[i]], genre_predict[genre_predict.columns.values[i]])\n",
    "    score = score/count_col\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing .StandardScaler().fit(x_train)\n",
    "x_train_np = scaler.transform(x_train)\n",
    "x_test_np = scaler.transform(x_test)\n",
    "\n",
    "indexs_train = x_train.index\n",
    "indexs_test = x_test.index\n",
    "x_train = pd.DataFrame(x_train_np, index = indexs_train, columns = x_train.columns)\n",
    "x_test = pd.DataFrame(x_test_np, index = indexs_test, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### methods support multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2734998744506037"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNN(n_neighbors=1)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "y_pred= pd.DataFrame(y_pred, columns = y_test.columns.values)\n",
    "score_knn = f1_genres(y_test, y_pred)\n",
    "score_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhengguo\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16952043858096622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree = DecisionTree(max_depth=6)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(x_test)\n",
    "y_pred= pd.DataFrame(y_pred, columns = y_test.columns.values)\n",
    "score_tree = f1_genres(y_test, y_pred)\n",
    "score_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1353949600455715"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForest()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(x_test)\n",
    "y_pred= pd.DataFrame(y_pred, columns = y_test.columns.values)\n",
    "score_rf = f1_genres(y_test, y_pred)\n",
    "score_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classifiers\n",
    "These classifiers don't support multilabel classification, thus need to fit classifier for each genre, then combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.310900618511\n"
     ]
    }
   ],
   "source": [
    "#Unweighted logistic regression\n",
    "\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    unweighted_logistic = LogisticRegression()\n",
    "    unweighted_logistic.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= unweighted_logistic.predict(x_test)\n",
    "\n",
    "score_unweighted_log = f1_genres(y_test, genre_pred)\n",
    "print score_unweighted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.379186272696\n"
     ]
    }
   ],
   "source": [
    "#weighted logistic regression\n",
    "\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "    weighted_logistic.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= weighted_logistic.predict(x_test)\n",
    "\n",
    "score_weighted_log = f1_genres(y_test, genre_pred)\n",
    "print score_weighted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhengguo\\Anaconda2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:389: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.313788098572\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    lda = LDA()\n",
    "    lda.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= lda.predict(x_test)\n",
    "\n",
    "score_lda = f1_genres(y_test, genre_pred)\n",
    "print score_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhengguo\\Anaconda2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:694: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.193498634524\n"
     ]
    }
   ],
   "source": [
    "#QDA\n",
    "\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    qda = QDA()\n",
    "    qda.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= qda.predict(x_test)\n",
    "\n",
    "score_qda = f1_genres(y_test, genre_pred)\n",
    "print score_qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.386071061144\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    svm = SVC(C=5, class_weight='balanced')\n",
    "    svm.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= svm.predict(x_test)\n",
    "\n",
    "score_svm = f1_genres(y_test, genre_pred)\n",
    "print score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>lda</th>\n",
       "      <th>qda</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "      <th>unweighted logistic</th>\n",
       "      <th>weighted logistic</th>\n",
       "      <th>weighted svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.313788</td>\n",
       "      <td>0.193499</td>\n",
       "      <td>0.135395</td>\n",
       "      <td>0.16952</td>\n",
       "      <td>0.310901</td>\n",
       "      <td>0.379186</td>\n",
       "      <td>0.386071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             knn       lda       qda        rf     tree  unweighted logistic  \\\n",
       "f1_score  0.2735  0.313788  0.193499  0.135395  0.16952             0.310901   \n",
       "\n",
       "          weighted logistic  weighted svm  \n",
       "f1_score           0.379186      0.386071  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({'knn': score_knn, \n",
    "                         'tree': score_tree,\n",
    "                         'rf': score_rf,\n",
    "                         'unweighted logistic': score_unweighted_log,\n",
    "                         'weighted logistic': score_weighted_log,\n",
    "                         'lda': score_lda,\n",
    "                         'qda': score_qda,                        \n",
    "                         'weighted svm': score_svm}, index = ['f1_score'])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By briefly checking , we found that weighted logistic regression and weighted SVM performs best here\n",
    "#### Thus we tune the parameter C for each columns to optimize its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function F_score takes model, predictors X and true y values and returns f1_score\n",
    "# this function is modified to suit cross validation format\n",
    "\n",
    "def F_score_cv(model, X, y_true):\n",
    "    y_predict = model.predict(X)\n",
    "    score = f1_score(y_predict, y_true)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 0.01\n",
      "Adventure 0.001\n",
      "Comedy 0.0001\n",
      "Crime 0.01\n",
      "Fantasy 0.001\n",
      "Family 10\n",
      "Romance 0.001\n",
      "Horror 1000\n",
      "Western 100000\n",
      "Documentary 0.1\n",
      "Biography 0.01\n",
      "Drama 0.001\n",
      "Animation 100\n",
      "Sci-Fi 100\n",
      "Thriller 0.001\n",
      "Short 0.01\n",
      "Mystery 0.1\n",
      "Sport 0.01\n",
      "War 0.01\n",
      "History 1\n",
      "Music 10\n",
      "Foreign 100\n",
      "Other 0.001\n",
      "0.372648609453\n"
     ]
    }
   ],
   "source": [
    "genre_pred = pd.DataFrame(index = x_test.index) # dataframe to store predicted values\n",
    "\n",
    "for col in y_train.columns:\n",
    "    k_cv = 5\n",
    "    score_cv = []\n",
    "    for i in range(-6, 7, 2):\n",
    "        # fit regularized logistic regression model on training set      \n",
    "        weighted_logistic = LogisticRegression(class_weight='balanced', C = 10**i)\n",
    "        score_cv += [sum(cross_val_score(weighted_logistic, x_train, y_train[col], cv = k_cv, scoring = F_score_cv)) / k_cv]\n",
    "    # find best score and corresponding tuning parameter\n",
    "    max_value = max(score_cv)\n",
    "    max_index = score_cv.index(max_value)\n",
    "    C_best = 10**(max_index -7)\n",
    "    print col, C_best\n",
    "    weighted_logistic = LogisticRegression(class_weight='balanced',  C = C_best)\n",
    "    weighted_logistic.fit(x_train, y_train[col])\n",
    "    genre_pred[col]= weighted_logistic.predict(x_test)\n",
    "\n",
    "score_weighted_log = f1_genres(y_test, genre_pred)\n",
    "print score_weighted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function score_genre\n",
    "# input: two pandas dataframes, \n",
    "    # genre_real: predicted values\n",
    "    # genre_predict: real values\n",
    "# output: mean accuracy of prediction\n",
    "# accuracy score here is defined as \n",
    "    # (intersection between real and predicted vectors) / (union between real and predicted vectors)\n",
    "\n",
    "def score_genre(genre_real, genre_predict):\n",
    "    count_row = len(genre_real)\n",
    "    if count_row == 0:\n",
    "        print \"No data in dataframe!\"\n",
    "        return\n",
    "    if count_row != len(genre_predict):\n",
    "        print \"Different length of predicted and real dataframes!\"\n",
    "        return\n",
    "    count_col = len(genre_real.columns)\n",
    "    if count_col == 0:\n",
    "        print \"No data in dataframe!\"\n",
    "        return\n",
    "    if count_col != len(genre_predict.columns):\n",
    "        print \"Different genres of predicted and real dataframes!\"\n",
    "        return\n",
    "    accuracy_genre = 0.0\n",
    "    for i in range(count_row):\n",
    "        count_intersection = 0.0\n",
    "        count_unity = 0.0\n",
    "        accuracy_temp = 0.0\n",
    "        for j in range(len(genre_real.columns)):\n",
    "            if genre_real.iloc[i][j] == 1 or genre_predict.iloc[i][j] == 1:\n",
    "                count_unity += 1.0\n",
    "            if genre_real.iloc[i][j] == 1 and genre_predict.iloc[i][j] == 1:\n",
    "                count_intersection += 1.0 \n",
    "        if count_unity == 0: # a few ovservations has no genre assigned, delete these values from evaluation\n",
    "            count_row = count_row - 1\n",
    "        else:\n",
    "            accuracy_temp = count_intersection / count_unity\n",
    "            accuracy_genre += accuracy_temp\n",
    "    if count_row <= 0:\n",
    "        print \"No meaning value!\"\n",
    "        return\n",
    "    return (accuracy_genre/count_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2712393269038586"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_genre(y_test, genre_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
